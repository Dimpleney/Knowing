# åŸºç¡€åŠŸèƒ½demo
# é›†æˆäº†å‘é‡æ•°æ®åº“Chromaçš„RAGçŸ¥è¯†åº“æŸ¥è¯¢+è‡ªåŠ¨å‘é€é‚®ä»¶

import os
import shutil
import time
from dotenv import load_dotenv
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import json
from openai import OpenAI
import streamlit as st
from llama_index.core import VectorStoreIndex, Settings,SimpleDirectoryReader,StorageContext
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding
from fuzzywuzzy import process
import re
from config import settings
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb
from chroma import query_with_RAG

GPT_MODEL = "gpt-4o-mini"

load_dotenv()
# è·å–ç¯å¢ƒå˜é‡
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AUTHORIZATION_CODE = os.getenv("AUTHORIZATION_CODE")

# client = openai.OpenAI(api_key=OPENAI_API_KEY)
client = OpenAI(base_url="https://api.openai-proxy.org/v1",
                api_key=OPENAI_API_KEY)
tools = [
    {
        "type": "function",
        "function": {
            "name": "send_email",
            "description": "Send an email to the specified email with the subject and content",
            "parameters": {
                "type": "object",
                "properties": {
                    "FromEmail": {
                        "type": "string",
                        "description": "The email address, eg., remember0101@126.com",
                    },
                    "Subject": {
                        "type": "string",
                        "description": "Subject of the email",
                    },
                    "Body": {
                        "type": "string",
                        "description": "The content of the email",
                    },
                    "Recipients": {
                        "type": "string",
                        "description": "The recipients' email addresses",
                    }
                },
                "required": ["FromEmail", "Subject", "Body", "Recipients"],
            },
        }
    }
]

st.sidebar.header("ğŸ“ƒ Dialgue Session:")

# å®šä¹‰ Prompt åº“
KNOWLEDGE_BASE_KEYWORDS = [
    "çŸ¥è¯†åº“", "çŸ¥è¯†åº“æŸ¥è¯¢", "æ–‡æ¡£", "èµ„æ–™", "ä¿¡æ¯",
    "notion", "Notion", "æ£€ç´¢", "æŸ¥æ‰¾", "æœç´¢", "æŸ¥è¯¢","DrugBAN"
]


# é…ç½®åŸºç¡€è®¾ç½®
Settings.embed_model = OllamaEmbedding(
    model_name="deepseek-r1:7b"
)
Settings.llm = Ollama(
    model="deepseek-r1:7b",
    request_timeout=360
)

def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            tools=tools,
            tool_choice=tool_choice,
        )
        return response
    except Exception as e:
        print("Unable to generate ChatCompletion response")
        print(f"Exception: {e}")
        return e

def send_email(sender_email, sender_authorization_code, recipient_email, subject, body):
    # åˆ›å»º MIMEMultipart å¯¹è±¡
    message = MIMEMultipart()
    message["From"] = sender_email
    message["To"] = recipient_email
    message["Subject"] = subject

    message.attach(MIMEText(body, "plain"))

    # åˆ›å»º SMTP_SSL ä¼šè¯
    with smtplib.SMTP_SSL("smtp.163.com", 465) as server:
        server.login(sender_email, sender_authorization_code)
        text = message.as_string()
        server.sendmail(sender_email, recipient_email, text)

# æç¤ºè¯
def should_query_knowledge_base(prompt: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥å¯åŠ¨çŸ¥è¯†åº“æŸ¥è¯¢
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å…³é”®è¯
    pattern = r"(çŸ¥è¯†åº“|æ–‡æ¡£|èµ„æ–™|ä¿¡æ¯|notion|æ£€ç´¢|æŸ¥æ‰¾|æœç´¢|æŸ¥è¯¢)"
    if re.search(pattern, prompt, re.IGNORECASE):
        return True
    
    # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ£€æŸ¥è¾“å…¥æ˜¯å¦åŒ…å« Prompt åº“ä¸­çš„å…³é”®è¯
    for keyword in KNOWLEDGE_BASE_KEYWORDS:
        match_score = process.extractOne(keyword, [prompt])[1]
        if match_score >= 80:  # ç›¸ä¼¼åº¦é˜ˆå€¼
            return True
    return False

# çŸ¥è¯†åº“æŸ¥è¯¢-æ— å‘é‡æ•°æ®åº“
def query_knowledge_base(question: str):
    
    # """
    # æŸ¥è¯¢ä¸ªäººçŸ¥è¯†åº“å¹¶è¿”å›ç­”æ¡ˆ
    # """
    # é…ç½®è·¯å¾„
    md_folder = "./data/mds"  # ä¿®æ”¹ä¸ºä½ çš„Markdownæ–‡ä»¶å¤¹è·¯å¾„
    
    # åŠ è½½å¹¶å¤„ç†æ–‡æ¡£
    documents = SimpleDirectoryReader(md_folder).load_data()
    index = VectorStoreIndex.from_documents(documents)
    # ç¼“å­˜ç´¢å¼•å¯¹è±¡é¿å…é‡å¤åŠ è½½
    # if "knowledge_index" not in st.session_state:
    #     st.session_state.knowledge_index = VectorStoreIndex.from_documents(documents)
    # index = st.session_state.knowledge_index
    # åˆ›å»ºæŸ¥è¯¢å¼•æ“
    query_engine = index.as_query_engine(
        similarity_top_k=3,
        verbose=True  # æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹
    )
    # æ·»åŠ å›ç­”æ¨¡æ¿
    prompt_template = f"""
    [æŒ‡ä»¤] è¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
    <thinking>ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ˆåˆ†æç”¨æˆ·æ„å›¾ï¼Œæ£€ç´¢ç­–ç•¥ç­‰ï¼‰</thinking>
    <answer>ç»“æ„åŒ–å›ç­”å†…å®¹</answer>
    """
    # æ‰§è¡ŒæŸ¥è¯¢
    response = query_engine.query(prompt_template + "\n\nç”¨æˆ·é—®é¢˜ï¼š" + question)
    return str(response)




# æ–°å¢å“åº”è§£æå‡½æ•°
def parse_response(raw_response: str) -> dict:
    thinking_match = re.search(r'<thinking>(.*?)</thinking>', raw_response, re.DOTALL)
    answer_match = re.search(r'<answer>(.*?)</answer>', raw_response, re.DOTALL)
    
    return {
        "thinking": thinking_match.group(1).strip() if thinking_match else "",
        "answer": answer_match.group(1).strip() if answer_match else raw_response
    }


def main():
    
    
    ###########---ui----############
    st.title("ğŸªª Knowing")

    # Initialize chat history
    # åˆå§‹åŒ–èŠå¤©å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []
    # åœ¨ä¾§è¾¹æ æ·»åŠ æ§åˆ¶é¡¹
    if st.sidebar.button("æ¸…ç©ºå†å²"):
        st.session_state.messages = []
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
    # åœ¨ä¾§è¾¹æ æ·»åŠ æ¨¡å‹é€‰æ‹©
#     selected_model = st.sidebar.selectbox(
#     "é€‰æ‹©æ¨¡å‹",
#     ("deepseek-r1:7b", "gpt-4")
# )
    # æ€§èƒ½ç›‘æ§
    start = time.time()
    # ä¸Šä¼ æ–‡æ¡£
    # with st.sidebar:
    #     st.header("ğŸ“ çŸ¥è¯†åº“ç®¡ç†")  # æ–°å¢ä¾§è¾¹æ æ¨¡å—
    #     uploaded_files = st.file_uploader(
    #         "ä¸Šä¼ çŸ¥è¯†æ–‡æ¡£ï¼ˆæ”¯æŒPDF/Word/Markdown/TXTï¼‰",
    #         type=["pdf", "docx", "md", "txt"],
    #         accept_multiple_files=True,
    #         help="æ¯æ¬¡ä¸Šä¼ åè‡ªåŠ¨æ›´æ–°çŸ¥è¯†åº“"
    #     )
    ###########---ui----############
    # upload_files(uploaded_files)
    

    # st.chat_inputï¼šåˆ›å»ºè¾“å…¥æ¡†ï¼Œæç¤ºç”¨æˆ·è¾“å…¥æ¶ˆæ¯
    # è‹¥ç”¨æˆ·è¾“å…¥ï¼Œåˆ™å°†å…¶èµ‹å€¼ç»™promtå˜é‡
    if prompt := st.chat_input("What is your message?"):
        # Display user message in chat message container
        # ä½¿ç”¨ st.chat_message æ˜¾ç¤ºç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯ï¼Œè§’è‰²ä¸º "user"
        st.chat_message("user").markdown(prompt)
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})

        # åˆ¤æ–­æ˜¯å¦åº”è¯¥å¯åŠ¨çŸ¥è¯†åº“æŸ¥è¯¢
        if should_query_knowledge_base(prompt):
            print("å¯åŠ¨çŸ¥è¯†åº“æŸ¥è¯¢")
            # åœ¨main()ä¸­æ›¿æ¢åŸæœ‰å“åº”å¤„ç†é€»è¾‘
            # knowledge_response = query_knowledge_base(prompt)
            knowledge_response = query_with_RAG(prompt)
            
            parsed = parse_response(knowledge_response)  # æ–°å¢è§£ææ­¥éª¤
            print("çŸ¥è¯†åº“æŸ¥è¯¢å®Œæˆ")
            
            # æ„å»ºç»“æ„åŒ–æ¶ˆæ¯å†…å®¹
            formatted_response = f"""
            â€‹**æ€è€ƒè¿‡ç¨‹**:\n{parsed['thinking']}\n\n
            â€‹**æ­£å¼å›ç­”**:\n{parsed['answer']}
            """
            with st.chat_message("assistant"):
                st.markdown(f"**æ€è€ƒè¿‡ç¨‹**:\n{parsed['thinking']}")  # å¯é€‰æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
                st.markdown(f"**æ­£å¼å›ç­”**:\n{parsed['answer']}")
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": formatted_response
                })
            # # æ˜¾ç¤ºå¹¶å­˜å‚¨å®Œæ•´æ¶ˆæ¯
            
        else:
            # Handle other types of prompts (e.g., chat completion)
            response = chat_completion_request(
                messages=st.session_state.messages,
                tools=tools
            )
            # st.sidebar.json(st.session_state)
            # st.sidebar.write(response)
            # Display assistant response in chat message container
            with st.chat_message("assistant"):
                if content := response.choices[0].message.content:
                    st.markdown(content)
                    st.session_state.messages.append({"role": "assistant", "content": content})
                # RAG
                else:
                    fn_name = response.choices[0].message.tool_calls[0].function.name
                    fn_args = response.choices[0].message.tool_calls[0].function.arguments

                    def confirm_send_fn():
                        send_email(
                            sender_email=args["FromEmail"],
                            sender_authorization_code=AUTHORIZATION_CODE,
                            recipient_email=args["Recipients"],
                            subject=args["Subject"],
                            body=args["Body"],
                        )
                        st.success("é‚®ä»¶å·²å‘é€")
                        st.session_state.messages.append({"role": "assistant", "content": "é‚®ä»¶å·²å‘é€ï¼Œè¿˜éœ€è¦ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ"})
                        # Refresh sidebar
                        st.sidebar.json(st.session_state)
                        st.sidebar.write(response)

                    def cancel_send_fn():
                        st.warning("é‚®ä»¶å‘é€å·²å–æ¶ˆ")
                        st.session_state.messages.append({"role": "assistant", "content": "é‚®ä»¶å·²å–æ¶ˆï¼Œè¿˜éœ€è¦ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ"})
                        # Refresh sidebar
                        st.sidebar.json(st.session_state)
                        st.sidebar.write(response)

                    if fn_name == "send_email":
                        args = json.loads(fn_args)
                        st.markdown("é‚®ä»¶å†…å®¹å¦‚ä¸‹ï¼š")
                        st.markdown(f"å‘ä»¶äºº: {args['FromEmail']}")
                        st.markdown(f"æ”¶ä»¶äºº: {args['Recipients']}")
                        st.markdown(f"ä¸»é¢˜: {args['Subject']}")
                        st.markdown(f"å†…å®¹: {args['Body']}")

                        col1, col2 = st.columns(2)
                        with col1:
                            st.button(
                                label="âœ…ç¡®è®¤å‘é€é‚®ä»¶",
                                on_click=confirm_send_fn
                            )
                        with col2:
                            st.button(
                                label="âŒå–æ¶ˆå‘é€é‚®ä»¶",
                                on_click=cancel_send_fn
                            )
        
    st.sidebar.metric("å“åº”æ—¶é—´", f"{time.time()-start:.2f}s")
    
if __name__ == "__main__":
    main()
   
